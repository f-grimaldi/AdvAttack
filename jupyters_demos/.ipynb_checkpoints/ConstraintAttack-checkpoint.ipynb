{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fgrim\\Desktop\\AdvAttack\\src\n"
     ]
    }
   ],
   "source": [
    "cd src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loss import SpecificSoftmaxMSE\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\n\\n\\nnet = Net()\\nloss = SpecificSoftmaxMSE(neuron=2, y_true=0, dim=1)\\noptim = ZeroSGD(model=net, loss=loss)\\n\\nx = torch.tensor([1])\\nx, loss_curve, out, xs = optim.run(x.view(1, 1, 1), v, m, a, epsilon=0.5,\\n                            max_steps=epoch, stop_criterion = 0,\\n                            max_aux_step = 100, verbose=0, additional_out=True)\\n\\nmin_, max_ = min(xs), max(xs)\\nlosses = []\\nfor i in tqdm(range(int(min_-1)*10, int(max_+1)*10)):\\n    x = torch.tensor([i/10]).to(torch.device('cuda'))\\n    out = net(x.view(1, 1, 1, 1))\\n    losses.append(loss(out))\\n\\nplt.plot([i/10 for i in range(int(min_-1)*10, int(max_+1)*10)], losses, label='Loss curve')\\nplt.scatter(xs, loss_curve, label='Parameters')\\nplt.legend()\\nplt.xlabel('Input')\\nplt.ylabel('Loss')\\nplt.title('Loss function')\\nplt.grid()\\nplt.show()\\n\""
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Classic version of the Zero-order Stochastic Gradient method (ZeroSGD)\n",
    "\"\"\"\n",
    "class ZeroSGD(object):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "    Name            Type                Description\n",
    "    model:          (nn.Module)         The model to use to get the output\n",
    "    loss:           (nn.Module)         The loss to minimize\n",
    "    device:\n",
    "    \"\"\"\n",
    "    def __init__(self, model, loss, device=torch.device('cuda')):\n",
    "        self.device = device\n",
    "        self.loss = loss\n",
    "        self.model = model.to(self.device)\n",
    "        self.model.eval()\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    Perform a zero-order optimization\n",
    "    \"\"\"\n",
    "    def run(self, x, v, mk, ak, epsilon, max_steps=100, \n",
    "            stop_criterion = 1e-10, max_aux_step = 100, \n",
    "            verbose=0, additional_out=False,\n",
    "            tqdm_disable=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        Name            Type                Description\n",
    "        x:              (torch.tensor)      The variable of our optimization problem\n",
    "        v:              (float)             The gaussian smoothing\n",
    "        mK:             (list)              A list of the the number of normal vector to generate at every step\n",
    "        aK:             (list)              The momentum to use at every step\n",
    "        epsilon:        (float)             The upper bound of the infinity norm\n",
    "        max_steps:      (int)               The maximum number of steps\n",
    "        stop_criterion  (float)             TODO\n",
    "        max_aux_step    (int)               TODO\n",
    "        verbose:        (bool)              Display information or not. Default is 0\n",
    "        \"\"\"\n",
    "        self.total_dim = x.shape[0]*x.shape[1]*x.shape[2]\n",
    "        self.dim  = x.shape\n",
    "        x = x.reshape(1, self.dim[0], self.dim[1], self.dim[2])\n",
    "        self.mins = (x.clone() - epsilon).view(-1).to(self.device)\n",
    "        self.max  = (x.clone() + epsilon).view(-1).to(self.device)\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "        # Init list for results\n",
    "        losses, outs = [], [] #List of losses and outputs\n",
    "        xs = []\n",
    "\n",
    "        # Optimizaion Cycle\n",
    "        self.x = x\n",
    "        for ep in tqdm(range(max_steps), disable=tqdm_disable):\n",
    "            # Call the step\n",
    "            x, Gk, uk = self.step(x, v, mk[ep], ak[ep], verbose)\n",
    "            # Project on boundaries\n",
    "            if verbose:\n",
    "                print('Shape of x: {}'.format(x.shape))\n",
    "                print('Shape of min: {}'.format(self.mins.shape))\n",
    "                print('Shape of max: {}'.format(self.max.shape))\n",
    "            x[self.max-x<0] = self.max[self.max-x<0]\n",
    "            x[x-self.mins<0] = self.mins[x-self.mins<0]\n",
    "            # Compute new loss\n",
    "            x = x.reshape(1, self.dim[0], self.dim[1], self.dim[2])\n",
    "            if additional_out:\n",
    "                xs.append(x.detach().cpu())\n",
    "            out  = self.model(x)\n",
    "            loss = self.loss(out)\n",
    "            # Save results\n",
    "            #xs.append(x.cpu().detach().numpy())\n",
    "            outs.append(out.cpu()[0, self.loss.neuron].item())\n",
    "            losses.append(loss.cpu().item())\n",
    "            # Display current info\n",
    "            if verbose:\n",
    "                print('---------------------------')\n",
    "                print('Step number: {}'.format(ep))\n",
    "                print('x:  {}'.format(x))\n",
    "                print('New loss:    {}'.format(loss.cpu().item()))\n",
    "            if loss < stop_criterion:\n",
    "                break\n",
    "\n",
    "        # Return\n",
    "        if additional_out:\n",
    "            return x, losses, outs, xs\n",
    "        return x, losses, outs\n",
    "\n",
    "    \"\"\"\n",
    "    Do an optimization step\n",
    "    \"\"\"\n",
    "    def step(self, x, v, mk, ak, verbose=0):\n",
    "        # 1 .Create x(k-1) and add a first dimension indicating that we are using an input with batch size equals 1\n",
    "        x = x.float().to(self.device)\n",
    "        # 2.Create x(k-1) + v*u(k-1)\n",
    "        uk     = self.generate_uk(mk)                                                   # Dim (mk, channel*width*height)\n",
    "        img_u  = uk.reshape(mk, self.dim[0], self.dim[1], self.dim[2]).to(self.device)  # Dim (mk, channel, width, height)\n",
    "        img_x  = x.expand(mk, self.dim[0], self.dim[1], self.dim[2])                    # Dim (mk, channel, width, height)\n",
    "        m_x    = (img_x + v*img_u)                                                      # Dim (mk, channel, width, height)\n",
    "\n",
    "        if verbose > 1:\n",
    "            print('INPUT')\n",
    "            print('The Gaussian vector uk has shape:{}'.format(uk.shape))\n",
    "            print('The input x has shape:\\t\\t{}'.format(x.shape))\n",
    "            print('The input x + vu has shape:\\t{}'.format(m_x.shape))\n",
    "\n",
    "        # 3. Get objective functions\n",
    "        standard_loss = self.loss(self.model(x))                                            # Dim (1)\n",
    "        gaussian_loss = self.loss(self.model(m_x))                                          # Dim (mk)\n",
    "        # 4. Compute gradient approximation\n",
    "        Gk  = self.compute_Gk(standard_loss, gaussian_loss, v, uk)                       # Dim (channel*width*height)\n",
    "\n",
    "        if verbose > 1:\n",
    "            print('OUTPUT')\n",
    "            print('F(x) has shape:\\t\\t\\t{}'.format(standard_loss.shape))\n",
    "            print('F(x + vu) has shape:\\t\\t{}'.format(gaussian_loss.shape))\n",
    "            # 4. Evaluate approximation of the gradient\n",
    "            print('GRADIENT APPROXIMATION')\n",
    "            print('G(u;v,k,x) has shape:\\t\\t{}'.format(Gk.shape))\n",
    "            print('Gradient: {}'.format(ak*Gk/torch.norm(Gk)))\n",
    "\n",
    "        # 4.Find the argmin\n",
    "        return x.reshape(-1) - ak*Gk/torch.norm(Gk), Gk, uk\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    Generate a random normal vector of size mk\n",
    "    \"\"\"\n",
    "    def generate_uk(self, mk):\n",
    "        return torch.empty(mk, self.total_dim).normal_(mean=0, std=1).to(self.device)\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    Compute objective function (loss) given an input for the model\n",
    "    \"\"\"\n",
    "    def compute_loss(self, x):\n",
    "        out = self.model(x)\n",
    "        loss = self.loss(out)\n",
    "        return loss\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    Compute the Gv(x(k-1), chi(k-1), u(k)) in order to compute an approximation of the gradient of f(x(k-1), chi(k-1))\n",
    "    \"\"\"\n",
    "    def compute_Gk(self, standard_loss, gaussian_loss, v, uk, verbose=0):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        Name            Type                Description\n",
    "        standard_loss:  (torch.tensor)      The loss given the input\n",
    "        gaussian_loss:  (torch.tensor)      The loss given the input with a gaussian vector\n",
    "        v:              (float)             The gaussian smoothing\n",
    "        uK:             (torch.tensor)      The random Normal vector\n",
    "        verbose:        (bool)              Display information or not. Default is 0\n",
    "        \"\"\"\n",
    "        # Compute Gv(x(k-1), chi(k-1), u(k))\n",
    "        fv = ((gaussian_loss - standard_loss.expand(uk.shape[0]))/v).view(-1, 1)             # Dim (mk, 1)\n",
    "        G =  fv * uk                                                                         # Dim (mk, channel*width*height)\n",
    "        return torch.mean(G, axis=0)                                                         # Dim (channel*width*height\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "net = Net()\n",
    "loss = SpecificSoftmaxMSE(neuron=2, y_true=0, dim=1)\n",
    "optim = ZeroSGD(model=net, loss=loss)\n",
    "\n",
    "x = torch.tensor([1])\n",
    "x, loss_curve, out, xs = optim.run(x.view(1, 1, 1), v, m, a, epsilon=0.5,\n",
    "                            max_steps=epoch, stop_criterion = 0,\n",
    "                            max_aux_step = 100, verbose=0, additional_out=True)\n",
    "\n",
    "min_, max_ = min(xs), max(xs)\n",
    "losses = []\n",
    "for i in tqdm(range(int(min_-1)*10, int(max_+1)*10)):\n",
    "    x = torch.tensor([i/10]).to(torch.device('cuda'))\n",
    "    out = net(x.view(1, 1, 1, 1))\n",
    "    losses.append(loss(out))\n",
    "\n",
    "plt.plot([i/10 for i in range(int(min_-1)*10, int(max_+1)*10)], losses, label='Loss curve')\n",
    "plt.scatter(xs, loss_curve, label='Parameters')\n",
    "plt.legend()\n",
    "plt.xlabel('Input')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss function')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv): Conv2d(1, 3, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
       "  (linear): Linear(in_features=27, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self, device=torch.device('cuda')):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(1, 3, (2, 2), stride=1, padding=1)\n",
    "        self.linear = nn.Linear(3*3*3, 2)\n",
    "        self.device = device\n",
    "        self = self.to(self.device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = nn.ReLU()(self.conv(x))\n",
    "        return self.linear(x.view(x.shape[0], -1))\n",
    "    \n",
    "    \n",
    "    def do_train(self, X, y, epoch):\n",
    "        loss_fn = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(self.parameters(), lr=0.001)\n",
    "        \n",
    "        losses, acc = [], []\n",
    "        bs = X.shape[0]//10\n",
    "        for ep in tqdm(range(epoch)):    \n",
    "            for n in range(10):\n",
    "                net.train()\n",
    "                batch_x, batch_y = X[n*bs:(n+1)*bs, :, :, :].to(self.device), y[n*bs:(n+1)*bs].to(self.device)\n",
    "                out = self(batch_x)\n",
    "                loss_batch = loss_fn(out, batch_y.long())\n",
    "                loss_batch.backward()\n",
    "                losses.append(loss_batch.item())\n",
    "                y_pred =  torch.argmax(out, axis=1).cpu()\n",
    "                acc.append(accuracy_score(batch_y.cpu().numpy(), y_pred.numpy()))\n",
    "                optimizer.step()\n",
    "            losses[ep] = np.mean(losses[-bs:])\n",
    "            acc[ep] = np.mean(acc[-bs:])\n",
    "        return losses[:ep], acc[:ep]\n",
    "\n",
    "    \n",
    "X = torch.randn(200, 4)\n",
    "\n",
    "\n",
    "net = Net(device=torch.device('cuda'))\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.randint(-1, 2, (200, 4)).float()\n",
    "Sum = torch.sum(X, axis = 1) + 10\n",
    "y = Sum.clone()\n",
    "y[y <= torch.mean(Sum)] = 0\n",
    "y[y >  torch.mean(Sum)] = 1\n",
    "X = X.reshape(-1, 1, 2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:09<00:00, 10.98it/s]\n"
     ]
    }
   ],
   "source": [
    "losses, acc = net.do_train(X, y, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses, label='Loss')\n",
    "plt.plot(acc, label='Accuracy')\n",
    "plt.xlabel('Steps')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: tensor([[[ 1.,  0.],\n",
      "         [ 1., -1.]]])\n",
      "Y_true: 1.0\n",
      "net(x): tensor([[-11.2035,  11.3149]], device='cuda:0', grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "dev = torch.device('cuda')\n",
    "x = X[0]\n",
    "print('X: {}'.format(x))\n",
    "print('Y_true: {}'.format(y[0]))\n",
    "print('net(x): {}'.format(net(x.to(dev).view(1, 1, 2, 2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 50\n",
    "m = [50]*epoch\n",
    "a = [0.1]*epoch\n",
    "v = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:00<00:00, 84.18it/s]\n"
     ]
    }
   ],
   "source": [
    "loss = SpecificSoftmaxMSE(neuron=1, y_true=0, dim=1)\n",
    "ADVoptim = ZeroSGD(model=net, loss=loss)\n",
    "x_out, loss_curve, out, xs = ADVoptim.run(x, v, m, a, epsilon=0.45,\n",
    "                             max_steps=epoch, stop_criterion = 0,\n",
    "                             max_aux_step = 100, verbose=0, additional_out=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting input \n",
      "tensor([[[ 1.,  0.],\n",
      "         [ 1., -1.]]])\n",
      "has output:\n",
      "tensor([[-11.2035,  11.3149]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "\n",
      "New input \n",
      "tensor([[[[ 0.5500, -0.4500],\n",
      "          [ 0.5500, -1.4500]]]], device='cuda:0', grad_fn=<AsStridedBackward>)\n",
      " has output:\n",
      "tensor([[0.2455, 0.0392]], device='cuda:0', grad_fn=<AddmmBackward>):\n"
     ]
    }
   ],
   "source": [
    "print('Starting input \\n{}\\nhas output:\\n{}\\n'.format(x, net(x.to(dev).view(1, 1, 2, 2))))\n",
    "print('New input \\n{}\\n has output:\\n{}:'.format(x_out, net(x_out)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([200, 1, 2, 2])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "def evaluate(e):\n",
    "    X_test = X[:10, ...]\n",
    "    success = []\n",
    "    xs = []\n",
    "    for x in X_test:\n",
    "        y_before = int(torch.argmax(net(x.to(dev).view(1, 1, 2, 2))))\n",
    "        loss = SpecificSoftmaxMSE(neuron=y_before, y_true=0, dim=1)\n",
    "        ADVoptim = ZeroSGD(model=net, loss=loss)\n",
    "        x_out, loss_curve, out, xs = ADVoptim.run(x, v, m, a, epsilon=e,\n",
    "                                 max_steps=epoch, stop_criterion = 1e-10,\n",
    "                                 max_aux_step = 100, verbose=0, additional_out=True,\n",
    "                                tqdm_disable=True)\n",
    "        if torch.argmax(net(x_out)) != y_before:\n",
    "            success.append(1)\n",
    "        else:\n",
    "            success.append(0)\n",
    "        xs.append(x_out)\n",
    "    return success, xs\n",
    "\n",
    "a1, b1 = evaluate(0.1)\n",
    "print(np.sum(a1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 10\n",
    "m = [20]*epoch\n",
    "a = [0.2]*epoch\n",
    "v = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:07<00:00,  1.14it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0,  4,  5,  8, 10, 10, 10, 10])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = []\n",
    "for e in tqdm(range(1, 9)):   \n",
    "    a1, _ = evaluate(e*0.1)\n",
    "    res.append(a1)\n",
    "np.sum(res, axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
