{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer description: ZSGD\n",
    "**Name:**  Zero Stochastic Gradient Descent <br>\n",
    "**Class:** zeroOptim.ZeroSGD <br>\n",
    "**Paper:** *Zeroth-order Nonconvex Stochastic Optimization: Handling Constraints, High-Dimensionality and Saddle-Points* (rishnakumar Balasubramanian†1 and Saeed Ghadimi‡2) <br>\n",
    "\n",
    "\n",
    "**Description:** <br>\n",
    "The zero-order Stochastic Gradient Descent its like the classical SGD but with the gradient G computed as follows:\n",
    "\n",
    "$$G_{v}^{k} \\equiv G_{v}(x_{k-1}, \\xi_{k}, u_{k}) = \\frac{1}{m_{k}} \\sum_{j=1}^{m_{k}} \\frac{F(x_{k-1} + vu_{k,j}, \\xi_{k,j}) - (x_{k-1}, \\xi_{k,j})}{v}u_{k,j}$$\n",
    "\n",
    "where: <br>\n",
    "$x_{k}$ is our optimization parameter <br>\n",
    "$\\xi_{k}$ is a sample of our distribution <br>\n",
    "$u_{k,j} \\sim N(0, I_{d})$ <br>\n",
    "$m_{k}$ is an input parameter <br>\n",
    "$v_{k}$ is the gaussian smoothing parameter\n",
    "\n",
    "**Args:**\n",
    "    \n",
    "    Name            Type                Description\n",
    "    x:              (torch.tensor)      The variable of our optimization problem. Should be a 3D tensor (img)\n",
    "    v:              (float)             The gaussian smoothing\n",
    "    n_gradient:     (list)              Number of normal vector to generate at every step. Its (mk)\n",
    "    ak              (list)              Pseudo learning rate every step\n",
    "    epsilon:        (float)             The upper bound of the infinity norm\n",
    "    L_type:         (int)               Either -1 for L_infinity or Lx for Lx. Default is -1\n",
    "    batch_size      (int)               Maximum parallelization number during gradient estimation. Default -1 (n_gradient)\n",
    "    C:              (tuple)             The boundaries of the pixel. Default is (0, 1)\n",
    "    max_steps:      (int)               The maximum number of steps. Default is 100\n",
    "    verbose:        (int)               Display information or not. Default is 0\n",
    "    additional_out  (bool)              Return also all the x. Default is False\n",
    "    tqdm_disable    (bool)              Disable the tqdm bar. Default is False\n",
    "     \n",
    "**Suggested values:**\n",
    "\n",
    "$v \\leq \\frac{1}{\\sqrt{L C\\log d}} min \\bigg\\{\\sqrt{\\frac{2\\sigma^2}{L}}, \\sqrt{\\frac{D_{0}LC}{2N\\sigma^2}}\\bigg\\}$, \n",
    "$\\alpha_{k} =\\frac{1}{2L C\\log d} min \\bigg\\{\\frac{1}{12s \\log d}, \\sqrt{\\frac{D_{0}}{N}}\\bigg\\}$,\n",
    "$m_{k} = 2(d + 5)N$,\n",
    "$\\forall k \\geq 1$\n",
    "\n",
    "where:<br>\n",
    "- *N* is the number of steps <br>\n",
    "- *d* is the dimension of *x* <br>\n",
    "- L is the Lipschitz Continuos Gradient Constant\n",
    "- $C \\geq \\frac{E\\big[||u||_{\\infty}^k\\big]}{\\sqrt{2\\log d^k}}$\n",
    "- $s \\geq ||\\nabla f(x)||_{0}, \\forall x \\in \\mathbb{R}^d$\n",
    "- $D_{0} \\geq f(x_{0}) - f^*$ <br>\n",
    "- $B_{L_{\\sigma}} ≥ max\\bigg\\{\\sqrt{\\frac{B^2 + \\sigma^2}{L}}, 1\\bigg\\}$\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
